{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "16969b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import re\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "504114a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"./report\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1c7b7706",
   "metadata": {},
   "outputs": [],
   "source": [
    "tex_path = \"../localvariables/Du.tex\"\n",
    "with open(tex_path) as f:\n",
    "    content = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "973e8133",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_newcommands(text):\n",
    "    commands = {}\n",
    "    current_value = []\n",
    "    i = 0\n",
    "    n = len(text)\n",
    "    \n",
    "    while i < n:\n",
    "        if text.startswith('\\\\newcommand{', i):\n",
    "            # Find the command name\n",
    "            start = i + len('\\\\newcommand{')\n",
    "            brace_count = 1\n",
    "            j = start\n",
    "            while j < n and brace_count > 0:\n",
    "                if text[j] == '{':\n",
    "                    brace_count += 1\n",
    "                elif text[j] == '}':\n",
    "                    brace_count -= 1\n",
    "                j += 1\n",
    "            command_name = text[start:j-1]\n",
    "            \n",
    "            # Find the command value\n",
    "            if j < n and text[j] == '{':\n",
    "                brace_count = 1\n",
    "                k = j + 1\n",
    "                current_value = []\n",
    "                while k < n and brace_count > 0:\n",
    "                    if text[k] == '{':\n",
    "                        brace_count += 1\n",
    "                    elif text[k] == '}':\n",
    "                        brace_count -= 1\n",
    "                    current_value.append(text[k])\n",
    "                    k += 1\n",
    "                command_value = ''.join(current_value[:-1])  # Remove the last '}'\n",
    "                commands[command_name] = command_value\n",
    "                i = k\n",
    "            else:\n",
    "                i = j\n",
    "        else:\n",
    "            i += 1\n",
    "    \n",
    "    return commands\n",
    "\n",
    "def extract_with_brace(text, brace):\n",
    "    pattern = r'\\\\begin\\{'+brace+r'\\}(.*?)\\\\end\\{' + brace + r'\\}'\n",
    "    matches = re.findall(pattern, text, re.DOTALL)\n",
    "    return matches\n",
    "\n",
    "def extract_with_head(text, head='section'):\n",
    "    result = dict()\n",
    "    pattern = r'\\\\' + re.escape(head) + r'\\{(.*?)\\}\\s*(.*?)(?=\\\\' + re.escape(head) + r'\\{|$)'\n",
    "    matches = re.findall(pattern, text, re.DOTALL)\n",
    "    if matches:\n",
    "        for key, value in matches:\n",
    "            result[key] = value.strip()  # 添加strip()去除可能的空白字符\n",
    "    return result if result else text\n",
    "\n",
    "def extract_command_firt_parameter(text, command):\n",
    "    pattern = r'\\\\' + re.escape(command) + r'{(.*?)}'\n",
    "    captions = re.findall(pattern, text)\n",
    "    return captions[0]\n",
    "\n",
    "def extract_tables(text):\n",
    "    tables = extract_with_brace(text, \"table\")\n",
    "    tables.extend(extract_with_brace(text, \"table\\*\"))\n",
    "    table_dict = dict()\n",
    "    for t in tables:\n",
    "        label = extract_command_firt_parameter(t, 'label')\n",
    "        table_dict[label] = t\n",
    "    return table_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "63b307a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_annotation(str):\n",
    "    return re.sub(r'%.*', '', str)\n",
    "\n",
    "\n",
    "def remove_newcommands(text):\n",
    "    result = []\n",
    "    i = 0\n",
    "    n = len(text)\n",
    "    stack = []\n",
    "    \n",
    "    while i < n:\n",
    "        if (i + len('\\\\newcommand') < n and \n",
    "            text[i:i+len('\\\\newcommand')] == '\\\\newcommand' and\n",
    "            (i == 0 or text[i-1] != '\\\\')):\n",
    "            \n",
    "            i += len('\\\\newcommand')\n",
    "            \n",
    "            while i < n and text[i].isspace():\n",
    "                i += 1\n",
    "                \n",
    "            if i < n and text[i] == '{':\n",
    "                stack.append('{')\n",
    "                i += 1\n",
    "                \n",
    "                command_name = []\n",
    "                while i < n and stack:\n",
    "                    if text[i] == '{':\n",
    "                        stack.append('{')\n",
    "                    elif text[i] == '}':\n",
    "                        stack.pop()\n",
    "                    if stack:\n",
    "                        command_name.append(text[i])\n",
    "                    i += 1\n",
    "                \n",
    "                if i < n and text[i] == '{':\n",
    "                    stack.append('{')\n",
    "                    i += 1\n",
    "                    \n",
    "                    while i < n and stack:\n",
    "                        if text[i] == '{':\n",
    "                            stack.append('{')\n",
    "                        elif text[i] == '}':\n",
    "                            stack.pop()\n",
    "                        i += 1\n",
    "            else:\n",
    "                pass\n",
    "        else:\n",
    "            result.append(text[i])\n",
    "            i += 1\n",
    "    \n",
    "    return ''.join(result)\n",
    "\n",
    "def remove_command_with_name(text, name):\n",
    "    command_start = '\\\\' + name + '{'\n",
    "    result = []\n",
    "    i = 0\n",
    "    n = len(text)\n",
    "    \n",
    "    while i < n:\n",
    "        start_pos = text.find(command_start, i)\n",
    "        if start_pos == -1:\n",
    "            result.append(text[i:])\n",
    "            break\n",
    "        \n",
    "        result.append(text[i:start_pos])\n",
    "        \n",
    "        i = start_pos + len(command_start)\n",
    "        \n",
    "        stack = 1  \n",
    "        \n",
    "        while i < n and stack > 0:\n",
    "            if text[i] == '{':\n",
    "                stack += 1\n",
    "            elif text[i] == '}':\n",
    "                stack -= 1\n",
    "            i += 1\n",
    "        \n",
    "        if stack != 0:\n",
    "            result.append(text[start_pos:i])\n",
    "    \n",
    "    return ''.join(result)\n",
    "\n",
    "\n",
    "def remove_single_line_command(text):\n",
    "    pattern = r'\\\\[a-zA-Z]*?\\n'\n",
    "    \n",
    "    result = re.sub(pattern, '\\n', text)\n",
    "    \n",
    "    return result\n",
    "\n",
    "def remove_redundant_newlines(text):\n",
    "    return re.sub(r'\\n{3,}', '\\n\\n', text).strip()\n",
    "\n",
    "\n",
    "def remove_with_brace(text, brace):\n",
    "    pattern = r'\\\\begin\\{'+brace+r'\\}.*?\\\\end\\{' + brace + r'\\}'\n",
    "    return re.sub(pattern, '', text, flags=re.DOTALL)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "93e2d35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_newcommands(text, newcommands):\n",
    "    for key, value in newcommands.items():\n",
    "        text = text.replace(key+\"{}\", value)\n",
    "    return text\n",
    "\n",
    "def process_AAAI_content(text, abstract):\n",
    "    segments = text.split('\\n\\n')\n",
    "    \n",
    "    paragraphs = [abstract] \n",
    "    \n",
    "    sections = []\n",
    "    subsections = []\n",
    "    \n",
    "    section_pattern = re.compile(r'\\\\section\\{(.*?)\\}')\n",
    "    subsection_pattern = re.compile(r'\\\\subsection\\{(.*?)\\}')\n",
    "    \n",
    "    para_id = 1\n",
    "    \n",
    "    para_to_section = {0: \"abstract\"}\n",
    "    section_to_para = {\"abstract\": [0]}\n",
    "    \n",
    "    para_to_subsection = {}\n",
    "    subsection_to_para = {}\n",
    "    \n",
    "    section_to_subsection = {}\n",
    "    subsection_to_section = {}\n",
    "    \n",
    "    current_section = \"abstract\"\n",
    "    current_subsection = None\n",
    "    \n",
    "    for seg in segments:\n",
    "        section_match = section_pattern.search(seg)\n",
    "        if section_match:\n",
    "            section_name = section_match.group(1)\n",
    "            sections.append(section_name)\n",
    "            current_section = section_name\n",
    "            current_subsection = None\n",
    "            continue\n",
    "        \n",
    "        subsection_match = subsection_pattern.search(seg)\n",
    "        if subsection_match:\n",
    "            subsection_name = subsection_match.group(1)\n",
    "            subsections.append(subsection_name)\n",
    "            current_subsection = subsection_name\n",
    "            if current_section not in section_to_subsection:\n",
    "                section_to_subsection[current_section] = []\n",
    "            section_to_subsection[current_section].append(current_subsection)\n",
    "            \n",
    "            subsection_to_section[current_subsection] = current_section\n",
    "\n",
    "            continue\n",
    "        \n",
    "        if not seg.strip().startswith('\\\\') and seg.strip() != '':\n",
    "            paragraphs.append(seg)\n",
    "            \n",
    "            # 更新段落与当前section的映射\n",
    "            if current_section not in section_to_para:\n",
    "                section_to_para[current_section] = []\n",
    "            section_to_para[current_section].append(para_id)\n",
    "            para_to_section[para_id] = current_section\n",
    "            \n",
    "            # 更新段落与当前subsection的映射（如果有）\n",
    "            if current_subsection:\n",
    "                if current_subsection not in subsection_to_para:\n",
    "                    subsection_to_para[current_subsection] = []\n",
    "                subsection_to_para[current_subsection].append(para_id)\n",
    "                para_to_subsection[para_id] = current_subsection\n",
    "            \n",
    "            para_id += 1\n",
    "    \n",
    "    # 构建结果字典\n",
    "    result = {\n",
    "        \"paragraphs\": paragraphs,\n",
    "        \"sections\": sections,\n",
    "        \"subsections\": subsections,\n",
    "        \"para_to_section\": para_to_section,\n",
    "        \"section_to_para\": section_to_para,\n",
    "        \"para_to_subsection\": para_to_subsection,\n",
    "        \"subsection_to_para\": subsection_to_para,\n",
    "        \"section_to_subsection\": section_to_subsection,\n",
    "        \"subsection_to_section\": subsection_to_section\n",
    "    }\n",
    "    \n",
    "    return result\n",
    "\n",
    "def inser_space_after_section(text):\n",
    "    # 匹配模式：\\xxxsection{yyy}\\nz\n",
    "    pattern = r'\\\\([a-zA-Z]+section)\\{(.*?)\\}\\n([a-zA-Z])'\n",
    "    \n",
    "    def replace_match(match):\n",
    "        section_cmd = match.group(1)  # xxxsection\n",
    "        content = match.group(2)      # yyy\n",
    "        char_after = match.group(3)   # z\n",
    "        \n",
    "        # 使用栈来验证括号是否平衡，并找到最外层括号的结束位置\n",
    "        stack = []\n",
    "        balanced_content = content\n",
    "        remaining_text = ''\n",
    "        \n",
    "        # 检查content中的括号是否平衡\n",
    "        for i, ch in enumerate(content):\n",
    "            if ch == '{':\n",
    "                stack.append('{')\n",
    "            elif ch == '}':\n",
    "                if stack:\n",
    "                    stack.pop()\n",
    "                else:\n",
    "                    # 不平衡的右括号，直接返回原匹配\n",
    "                    return match.group(0)\n",
    "        \n",
    "        # 如果栈不为空，说明有未闭合的左括号\n",
    "        if stack:\n",
    "            # 尝试从后续文本中寻找匹配的右括号\n",
    "            extended_content = content\n",
    "            text_after = text[match.end(2):]  # 获取匹配内容之后的文本\n",
    "            \n",
    "            for i, ch in enumerate(text_after):\n",
    "                extended_content += ch\n",
    "                if ch == '{':\n",
    "                    stack.append('{')\n",
    "                elif ch == '}':\n",
    "                    if stack:\n",
    "                        stack.pop()\n",
    "                        if not stack:  # 所有括号都匹配了\n",
    "                            # 更新content为扩展后的内容\n",
    "                            balanced_content = extended_content\n",
    "                            remaining_text = text_after[i+1:]\n",
    "                            break\n",
    "                    else:\n",
    "                        # 不平衡的右括号\n",
    "                        break\n",
    "            \n",
    "            # 如果栈仍然不为空，说明括号不平衡，返回原匹配\n",
    "            if stack:\n",
    "                return match.group(0)\n",
    "        \n",
    "        # 返回替换后的结果\n",
    "        return f'\\\\{section_cmd}{{{balanced_content}}}\\n\\n{char_after}'\n",
    "    \n",
    "    # 使用正则表达式进行替换\n",
    "    result = re.sub(pattern, replace_match, text)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f6753e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "content_1 = remove_annotation(content)\n",
    "table_dict = extract_tables(content_1)\n",
    "newcommands = extract_newcommands(content_1)\n",
    "content_2 = remove_newcommands(content_1)\n",
    "content_3 = extract_with_brace(content_2, \"document\")[0].strip()\n",
    "content_4 = content_3.replace(\"\\\\maketitle\", \"\")\n",
    "content_5 = remove_command_with_name(content_4, \"bibliography\")\n",
    "content_6 = remove_command_with_name(content_5, 'input')\n",
    "content_7 = remove_single_line_command(content_6)\n",
    "content_8 = remove_redundant_newlines(content_7)\n",
    "abstract = extract_with_brace(content_8, 'abstract')[0].strip()\n",
    "content_9 = remove_command_with_name(content_8, 'cite')\n",
    "content_10 = translate_newcommands(content_9, newcommands)\n",
    "content_11 = content_10.replace(\"\\n\\\\begin{equation}\", \"\\\\begin{equation}\")\n",
    "content_12 = remove_with_brace(content_11, \"abstract\").strip()\n",
    "content_13 = inser_space_after_section(content_12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "dc79d612",
   "metadata": {},
   "outputs": [],
   "source": [
    "para_tree = process_AAAI_content(content_13, abstract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c6c1d44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "localvariables = json.load(open(\"../localvariables/localvariables.json\"))\n",
    "api_key = localvariables['deepseek_api']\n",
    "base_url = \"https://api.deepseek.com\"\n",
    "\n",
    "client = OpenAI(api_key=api_key, base_url=base_url)\n",
    "\n",
    "\n",
    "def chat_with_llm(client, system_prompt, user_prompt):\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"deepseek-chat\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt},\n",
    "        ],\n",
    "        stream=False\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "76f7ff8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chat_with_llm(client, \"You are a helpful assistant\", \"Hello world\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "9874be62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_deductive_structure(client, paragraphs):\n",
    "    system_prompt = \"你是一个文本结构分析专家，需要判断段落是否符合总分或总分总结构。请用中文回答。\"\n",
    "    user_prompt_template = \"请分析以下段落是否符合总分或总分总结构：\\n\\n{}\"\n",
    "    \n",
    "    results = []\n",
    "    for para in tqdm(paragraphs, total=len(paragraphs)):\n",
    "        user_prompt = user_prompt_template.format(para)\n",
    "        para_result = chat_with_llm(client, system_prompt, user_prompt)\n",
    "        results.append({\n",
    "            'paragraph': para,\n",
    "            'analysis': para_result\n",
    "        })\n",
    "    \n",
    "    with open(\"./report/deductive_structure.md\", 'w', encoding='utf-8') as f:\n",
    "        for result in results:\n",
    "            f.write(\"---\\n\")\n",
    "            f.write(\"```\\n\")\n",
    "            f.write(f\"{result['paragraph']}\\n\")\n",
    "            f.write(\"```\\n\\n\")\n",
    "            f.write(\"LLM输出如下：\\n\")\n",
    "            f.write(f\"{result['analysis']}\\n\")\n",
    "            f.write(\"---\\n\\n\")\n",
    "\n",
    "def check_grammar(client, paragraphs):\n",
    "    # 系统提示词 - 明确模型角色和任务\n",
    "    system_prompt = \"\"\"你是一位专业的英语语法检查专家。你的任务是：\n",
    "    1. 仔细分析用户提供的英文段落\n",
    "    2. 识别并指出所有语法错误、拼写错误、标点错误和表达不自然的地方\n",
    "    3. 对每个错误提供详细的解释和修正建议\n",
    "    4. 最后给出一个修正后的完整段落版本\n",
    "    5. 如果段落没有错误，请明确指出该段落语法正确\n",
    "    \n",
    "    请使用以下格式进行回复：\n",
    "    - 总体评价: [简要评价段落的语法质量]\n",
    "    - 错误分析: \n",
    "      * [错误位置]: [错误描述] → [修正建议]\n",
    "      * (如果没有错误，写\"未发现语法错误\")\n",
    "    - 修正后的段落: [提供完整的修正后段落]\n",
    "    \"\"\"\n",
    "    \n",
    "    # 用户提示词模板\n",
    "    user_prompt_template = \"\"\"请仔细检查以下英文段落的语法、拼写、标点和表达是否准确自然：\n",
    "    \n",
    "    {}\n",
    "    \n",
    "    请按照要求的格式提供详细的语法分析。\"\"\"\n",
    "    \n",
    "    results = []\n",
    "    for para in tqdm.tqdm(paragraphs, total=len(paragraphs)):\n",
    "        # 跳过空段落\n",
    "        if not para.strip():\n",
    "            results.append({\n",
    "                'paragraph': para,\n",
    "                'analysis': \"段落为空，跳过检查\"\n",
    "            })\n",
    "            continue\n",
    "            \n",
    "        user_prompt = user_prompt_template.format(para)\n",
    "        para_result = chat_with_llm(client, system_prompt, user_prompt)\n",
    "        results.append({\n",
    "            'paragraph': para,\n",
    "            'analysis': para_result\n",
    "        })\n",
    "    \n",
    "    # 生成更详细的报告\n",
    "    with open(\"./report/grammar.md\", 'w', encoding='utf-8') as f:\n",
    "        f.write(\"# 语法检查报告\\n\\n\")\n",
    "        f.write(\"本文档包含对各个段落的语法检查结果。\\n\\n\")\n",
    "        \n",
    "        for i, result in enumerate(results, 1):\n",
    "            f.write(f\"## 段落 {i}\\n\")\n",
    "            f.write(\"---\\n\")\n",
    "            f.write(\"### 原始段落:\\n\")\n",
    "            f.write(\"```\\n\")\n",
    "            f.write(f\"{result['paragraph']}\\n\")\n",
    "            f.write(\"```\\n\\n\")\n",
    "            f.write(\"### 语法分析:\\n\")\n",
    "            f.write(f\"{result['analysis']}\\n\")\n",
    "            f.write(\"---\\n\\n\")\n",
    "\n",
    "\n",
    "def check_consistence_between_table_and_paragraph(client, paragraphs, table_dict):\n",
    "    check_paragraphs = []\n",
    "    for para in paragraphs:\n",
    "        for tk, tv in table_dict.items():\n",
    "            if tk in para:\n",
    "                check_paragraphs.append((tv, para))\n",
    "\n",
    "    system_prompt = \"\"\n",
    "    user_prompt_template = \"\"\n",
    "    \n",
    "    results = []\n",
    "    for table, para in tqdm(check_paragraphs, total=len(check_paragraphs)):\n",
    "        user_prompt = user_prompt_template.format(table, para)\n",
    "        para_result = chat_with_llm(client, system_prompt, user_prompt)\n",
    "        results.append({\n",
    "            'paragraph': para,\n",
    "            'analysis': para_result\n",
    "        })\n",
    "    \n",
    "    with open(\"./report/deductive_structure.md\", 'w', encoding='utf-8') as f:\n",
    "        for result in results:\n",
    "            f.write(\"---\\n\")\n",
    "            f.write(\"```\\n\")\n",
    "            f.write(f\"{result['paragraph']}\\n\")\n",
    "            f.write(\"```\\n\\n\")\n",
    "            f.write(\"LLM输出如下：\\n\")\n",
    "            f.write(f\"{result['analysis']}\\n\")\n",
    "            f.write(\"---\\n\\n\")\n",
    "\n",
    "\n",
    "def check_consistence_between_table_and_paragraph(client, paragraphs, table_dict):\n",
    "    # 构建系统提示词\n",
    "    system_prompt = \"\"\"你是一个数据一致性检测专家。你的任务是比较表格数据和段落描述，找出所有不一致的地方。\n",
    "    请仔细分析表格中的数据和段落中的描述，指出任何数字、事实或细节上的差异。\n",
    "    对于每个不一致之处，请明确指出：1) 表格中的值是什么 2) 段落中的描述是什么 3) 为什么不一致\n",
    "    如果完全一致，请明确指出\"表格数据与段落描述完全一致\"。\n",
    "    请保持客观、准确，只基于提供的数据进行分析。\"\"\"\n",
    "    \n",
    "    # 构建用户提示词模板\n",
    "    user_prompt_template = \"\"\"请分析以下表格数据与段落描述之间的一致性：\n",
    "    \n",
    "    表格数据：\n",
    "    {}\n",
    "    \n",
    "    段落描述：\n",
    "    {}\n",
    "    \n",
    "    请指出任何不一致的地方，包括但不限于数字、统计数据等方面的差异。\n",
    "    如果存在不一致，请具体说明哪些部分不一致，并指出表格和段落中的相应值。\n",
    "    如果完全一致，请明确说明。\"\"\"\n",
    "    \n",
    "    # 找出包含表格关键词的段落\n",
    "    check_paragraphs = []\n",
    "    for para in paragraphs:\n",
    "        for tk, tv in table_dict.items():\n",
    "            # 检查表格标识是否在段落中\n",
    "            if tk in para:\n",
    "                check_paragraphs.append((tv, para))\n",
    "    \n",
    "\n",
    "    results = []\n",
    "    for table, para in tqdm(check_paragraphs, total=len(check_paragraphs), desc=\"检查一致性\"):\n",
    "\n",
    "        user_prompt = user_prompt_template.format(table, para)\n",
    "        para_result = chat_with_llm(client, system_prompt, user_prompt)\n",
    "        results.append({\n",
    "            'table_data': table,\n",
    "            'paragraph': para,\n",
    "            'analysis': para_result\n",
    "        })\n",
    "    \n",
    "    # 保存结果到Markdown文件\n",
    "    with open(\"./report/deductive_structure.md\", 'w', encoding='utf-8') as f:\n",
    "        f.write(\"# 表格与段落一致性检查报告\\n\\n\")\n",
    "        \n",
    "        for i, result in enumerate(results, 1):\n",
    "            f.write(f\"## 检查项 {i}\\n\\n\")\n",
    "            f.write(\"### 表格数据\\n```json\\n\")\n",
    "            f.write(f\"{result['table_data']}\\n\")\n",
    "            f.write(\"```\\n\\n\")\n",
    "            f.write(\"### 段落描述\\n```\\n\")\n",
    "            f.write(f\"{result['paragraph']}\\n\")\n",
    "            f.write(\"```\\n\\n\")\n",
    "            f.write(\"### 一致性分析\\n\")\n",
    "            f.write(f\"{result['analysis']}\\n\\n\")\n",
    "            f.write(\"---\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a2e3e664",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check_deductive_structure(client, para_tree['paragraphs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "24ae9e95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "检查一致性: 100%|██████████| 5/5 [01:11<00:00, 14.28s/it]\n"
     ]
    }
   ],
   "source": [
    "check_consistence_between_table_and_paragraph(client, para_tree['paragraphs'], table_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006a3da3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852cdc59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2e84f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a6a48b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5889bdf9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333ad675",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
